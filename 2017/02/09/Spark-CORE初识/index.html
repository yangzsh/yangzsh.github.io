<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="大数据技术整理文档"><title>Spark CORE初识 | 博客</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark CORE初识</h1><a id="logo" href="/.">博客</a><p class="description">IT技术博客</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark CORE初识</h1><div class="post-meta">Feb 9, 2017<span> | </span><span class="category"><a href="/categories/Spark/">Spark</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark功能、优势，尤其与MapReduce相比较"><span class="toc-number">1.</span> <span class="toc-text">Spark功能、优势，尤其与MapReduce相比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能"><span class="toc-number">2.</span> <span class="toc-text">Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark四种模式"><span class="toc-number">2.1.</span> <span class="toc-text">Spark四种模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local模式安装"><span class="toc-number">2.2.</span> <span class="toc-text">Local模式安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#解压"><span class="toc-number">2.2.1.</span> <span class="toc-text">解压</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#修改相关参数"><span class="toc-number">2.2.2.</span> <span class="toc-text">修改相关参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#启动HDFS"><span class="toc-number">2.2.3.</span> <span class="toc-text">启动HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#测试"><span class="toc-number">2.2.4.</span> <span class="toc-text">测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#案例：WordCount"><span class="toc-number">2.3.</span> <span class="toc-text">案例：WordCount</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-Standlone安装部署启动及测试、编写实现WordCount程序"><span class="toc-number">3.</span> <span class="toc-text">Spark Standlone安装部署启动及测试、编写实现WordCount程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Standalone结构："><span class="toc-number">3.1.</span> <span class="toc-text">Standalone结构：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Yarn的结构："><span class="toc-number">3.1.1.</span> <span class="toc-text">Yarn的结构：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SparkStandalone的结构："><span class="toc-number">3.1.2.</span> <span class="toc-text">SparkStandalone的结构：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置安装："><span class="toc-number">3.2.</span> <span class="toc-text">配置安装：</span></a></li></ol></li></ol></div></div><div class="post-content"><h2 id="Spark功能、优势，尤其与MapReduce相比较"><a href="#Spark功能、优势，尤其与MapReduce相比较" class="headerlink" title="Spark功能、优势，尤其与MapReduce相比较"></a>Spark功能、优势，尤其与MapReduce相比较</h2><table>
<thead>
<tr>
<th>MapReduce</th>
<th>Spark</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据存储结构：磁盘hdfs文件系统的split</td>
<td>使用内存构建弹性分布式数据集RDD，对数据进行运算和cache</td>
</tr>
<tr>
<td>编程范式：Map+Reduce</td>
<td>DAG（有向无环图）：Transformation+action</td>
</tr>
<tr>
<td>计算中间数据落磁盘，io及序列化、反序列化代价大</td>
<td>计算中间数据在内存中维护，存取速度是磁盘的多个数量级</td>
</tr>
<tr>
<td>Task以进程的方式维护，任务启动就有数秒</td>
<td>Task以线程的方式维护，对小数据集的读取能达到亚秒级的延迟</td>
</tr>
</tbody>
</table>
<h2 id="Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能"><a href="#Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能" class="headerlink" title="Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能"></a>Spark提供交互性工具spark-shell的基本使用，以及初步理解RDD的功能</h2><h3 id="Spark四种模式"><a href="#Spark四种模式" class="headerlink" title="Spark四种模式"></a>Spark四种模式</h3><p>Local：本地运行模式，主要用于开发、测试<br>Standalone：使用Spark自带的资源管理框架运行Spark程序，30%左右<br>Yarn: 将spark应用程序运行在yarn上，绝大多数使用情况，60%左右<br>Mesos：</p>
<h3 id="Local模式安装"><a href="#Local模式安装" class="headerlink" title="Local模式安装"></a>Local模式安装</h3><p>使用自己编译产生的tgz压缩包<br>步骤：<br>前提：安装Scala（2.10.4）和JDK（1.7.x+）</p>
<h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tar -zxvf /opt/tools/workspace/spark<span class="number">-1.6</span><span class="number">.1</span>/spark<span class="number">-1.6</span><span class="number">.0</span>-bin<span class="number">-2.5</span><span class="number">.0</span>-cdh5<span class="number">.3</span><span class="number">.6</span>.tgz  -C /opt/cdh5<span class="number">.3</span><span class="number">.6</span></div><div class="line"></div><div class="line"> cd /opt/cdh5<span class="number">.3</span><span class="number">.6</span></div><div class="line"><span class="comment">//软链接</span></div><div class="line">ln -s spark<span class="number">-1.6</span><span class="number">.0</span>-bin<span class="number">-2.5</span><span class="number">.0</span>-cdh5<span class="number">.3</span><span class="number">.6</span>/ spark</div></pre></td></tr></table></figure>
<h4 id="修改相关参数"><a href="#修改相关参数" class="headerlink" title="修改相关参数"></a>修改相关参数</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">cd /opt/cdh5<span class="number">.3</span><span class="number">.6</span>/spark/conf</div><div class="line">mv spark-env.sh.template spark-env.sh</div><div class="line">mv spark-defaults.conf.template spark-defaults.conf</div><div class="line">vim spark-env.sh</div><div class="line">JAVA_HOME=/opt/modules/jdk1<span class="number">.7</span><span class="number">.0</span>_67</div><div class="line">SCALA_HOME=/opt/modules/scala<span class="number">-2.10</span><span class="number">.4</span></div><div class="line"></div><div class="line">HADOOP_CONF_DIR=/opt/cdh5<span class="number">.3</span><span class="number">.6</span>/hadoop<span class="number">-2.5</span><span class="number">.0</span>-cdh5<span class="number">.3</span><span class="number">.6</span>/etc/hadoop </div><div class="line"><span class="comment">//配置项：</span></div><div class="line"><span class="comment">//HADOOP_CONF_DIR：指定的spark依赖的hadoop环境的配置文件所在的文件夹，spark可以通过该参数配置的配置项中的配置连接到HDFS/Yarn上</span></div><div class="line"></div><div class="line">SPARK_LOCAL_IP=hadoop-senior01<span class="number">.30</span>wish.com</div></pre></td></tr></table></figure>
<h4 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h4><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="literal">start</span>-dfs.sh</div></pre></td></tr></table></figure>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">./bin/spark-<span class="built_in">shell</span></div><div class="line">......</div><div class="line"><span class="comment"></span></div><div class="line">// SparkCore开发</div><div class="line">scala&gt;  val textFile = sc.textFile(<span class="string">"README.md"</span>)</div><div class="line">textFile: org.apache.spark.rdd.RDD[String] = README.md MapPartitionsRDD[<span class="number">1</span>] <span class="keyword">at</span> textFile <span class="keyword">at</span> &lt;console&gt;:<span class="number">27</span></div><div class="line"></div><div class="line">scala&gt; textFile.count()</div><div class="line">res0: Long = <span class="number">95</span></div><div class="line"></div><div class="line">scala&gt; textFile.<span class="keyword">first</span>()</div><div class="line">res1: String = <span class="comment"># Apache Spark</span></div><div class="line"></div><div class="line">scala&gt; val linesWithSpark = textFile.<span class="built_in">filter</span>(<span class="built_in">line</span> =&gt; <span class="built_in">line</span>.<span class="keyword">contains</span>(<span class="string">"Spark"</span>))</div><div class="line">linesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[<span class="number">2</span>] <span class="keyword">at</span> <span class="built_in">filter</span> <span class="keyword">at</span> &lt;console&gt;:<span class="number">29</span></div><div class="line"></div><div class="line">scala&gt; textFile.<span class="built_in">filter</span>(<span class="built_in">line</span> =&gt; <span class="built_in">line</span>.<span class="keyword">contains</span>(<span class="string">"Spark"</span>)).count()</div><div class="line">res2: Long = <span class="number">17</span></div></pre></td></tr></table></figure>
<h3 id="案例：WordCount"><a href="#案例：WordCount" class="headerlink" title="案例：WordCount"></a>案例：WordCount</h3><ul>
<li><p>需求分析</p>
<ul>
<li><p>统计英文文章中单词出现的数量；一行英语语句中，使用空格分开大单独存在的单词认为英文单词；</p>
</li>
<li><p>数据来源：存储在HDFS上的英文单词txt文本</p>
</li>
<li><p>结果保存：最终统计数据输出到HDFS上</p>
</li>
</ul>
</li>
<li><p>实现方式</p>
<ul>
<li>SparkCore</li>
</ul>
</li>
</ul>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">val textFile = sc.textFile(<span class="string">"/input/wc.input"</span>)</div><div class="line"></div><div class="line">val wordCounts = textFile.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b)</div><div class="line"></div><div class="line">wordCounts.saveAsTextFile(<span class="string">"/output"</span>)</div><div class="line"></div><div class="line">[<span class="number">30</span>wish@hadoop-senior01 hadoop<span class="number">-2.5</span><span class="number">.0</span>-cdh5<span class="number">.3</span><span class="number">.6</span>]$ bin/hdfs dfs -text /output/part*</div><div class="line">(hive,<span class="number">2</span>)</div><div class="line">(jobtrack,<span class="number">1</span>)</div><div class="line">(solr,<span class="number">1</span>)</div><div class="line">(pig,<span class="number">1</span>)</div><div class="line">(tasktrack,<span class="number">1</span>)</div><div class="line">(datanode,<span class="number">5</span>)</div><div class="line">(nodemanager,<span class="number">4</span>)</div><div class="line">(phoenix,<span class="number">2</span>)</div><div class="line">(resourcemanager,<span class="number">1</span>)</div><div class="line">(namenode,<span class="number">7</span>)</div><div class="line">(hbase,<span class="number">1</span>)</div></pre></td></tr></table></figure>
<h2 id="Spark-Standlone安装部署启动及测试、编写实现WordCount程序"><a href="#Spark-Standlone安装部署启动及测试、编写实现WordCount程序" class="headerlink" title="Spark Standlone安装部署启动及测试、编写实现WordCount程序"></a>Spark Standlone安装部署启动及测试、编写实现WordCount程序</h2><h3 id="Standalone结构："><a href="#Standalone结构：" class="headerlink" title="Standalone结构："></a>Standalone结构：</h3><p>Standalone模式是Spark自身管理资源的一个模式，类似Yarn</p>
<h4 id="Yarn的结构："><a href="#Yarn的结构：" class="headerlink" title="Yarn的结构："></a>Yarn的结构：</h4><p>ResourceManager：负责集群资源的管理<br>NodeManager：负责当前机器的资源管理CPU&amp;内存</p>
<h4 id="SparkStandalone的结构："><a href="#SparkStandalone的结构：" class="headerlink" title="SparkStandalone的结构："></a>SparkStandalone的结构：</h4><p>Master：负责集群资源管理<br>Worker：负责当前机器的资源管理CPU&amp;内存</p>
<h3 id="配置安装："><a href="#配置安装：" class="headerlink" title="配置安装："></a>配置安装：</h3><p>前提：基于Local模式下的进行修改安装<br>前提2：所有机器以及完成SSH免密码登录</p>
<p>1.修改spark-env.sh<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">vim spark-env.sh</div><div class="line"></div><div class="line"><span class="attr">SPARK_MASTER_IP=hadoop-senior01.ibeifeng.com</span></div><div class="line"><span class="attr">SPARK_MASTER_PORT=7070</span></div><div class="line"><span class="attr">SPARK_MASTER_WEBUI_PORT=8080</span></div><div class="line"><span class="attr">SPARK_WORKER_CORES=3</span> <span class="comment">## 一个work分配的cpu数量</span></div><div class="line"><span class="attr">SPARK_WORKER_MEMORY=3g</span> <span class="comment">## 一个work分配的内存数量</span></div><div class="line"><span class="attr">SPARK_WORKER_PORT=7071</span></div><div class="line"><span class="attr">SPARK_WORKER_WEBUI_PORT=8081</span></div><div class="line"><span class="attr">SPARK_WORKER_INSTANCES=2</span> <span class="comment">## 一台机器允许同时存在的work的数量</span></div></pre></td></tr></table></figure></p>
<p>2.修改slaves.template，给定work节点的hostname<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv slaves.template slaves</div><div class="line">vim slaves ## 一行一个hostname</div></pre></td></tr></table></figure></p>
<p>3.启动服务<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">cd</span> /<span class="keyword">opt</span>/cdh-<span class="number">5.3</span>.<span class="number">6</span>/spark</div><div class="line"></div><div class="line">// 全部启动</div><div class="line">sbin/start-<span class="keyword">all</span>.<span class="keyword">sh</span></div><div class="line"></div><div class="line"></div><div class="line">/**</div><div class="line">*   分开启动</div><div class="line">*   ./sbin/start-master.<span class="keyword">sh</span></div><div class="line">*   ./sbin/start-slave.<span class="keyword">sh</span> spark://hadoop-senior01.<span class="number">30</span>wish.<span class="keyword">com</span>:<span class="number">7070</span> </div><div class="line"></div><div class="line">./sbin/start-slave.<span class="keyword">sh</span> <span class="symbol">&lt;master-spark-URL&gt;</span>中的<span class="symbol">&lt;master-spark-URL&gt;</span>是spark://hadoop-senior01.<span class="number">30</span>wish.<span class="keyword">com</span>:<span class="number">7070</span> </div><div class="line">**/</div><div class="line"></div><div class="line"></div><div class="line">日志位于:/<span class="keyword">opt</span>/cdh-<span class="number">5.3</span>.<span class="number">6</span>/spark/logs文件夹中</div><div class="line">访问页面：http://hadoop-senior01:<span class="number">8080</span>/</div></pre></td></tr></table></figure></p>
<p>4.测试wordcount程序<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 打开命令Client</span></div><div class="line"></div><div class="line">bin/spark-<span class="keyword">shell</span> --master spark:<span class="comment">//hadoop-senior01.30wish.com:7070</span></div><div class="line"></div><div class="line">具体代码参考以上<span class="keyword">Local</span>模式的<span class="built_in">WordCount</span></div></pre></td></tr></table></figure></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://yangzsh.github.io/2017/02/09/Spark-CORE初识/" data-id="ciyy694go000424qz21cldmcp" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Spark-CORE/">Spark CORE</a></div><div class="post-nav"><a href="/2017/02/07/Spark RDD理解/" class="next">Spark RDD理解</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://yangzsh.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HBase二次索引/">HBase二次索引</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/">Scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境搭建/">环境搭建</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/MR开发环境搭建/" style="font-size: 15px;">MR开发环境搭建</a> <a href="/tags/Scala语法/" style="font-size: 15px;">Scala语法</a> <a href="/tags/Spark-CORE/" style="font-size: 15px;">Spark CORE</a> <a href="/tags/Spark-RDD/" style="font-size: 15px;">Spark RDD</a> <a href="/tags/Spark源码编译/" style="font-size: 15px;">Spark源码编译</a> <a href="/tags/Phoenix/" style="font-size: 15px;">Phoenix</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/02/09/Spark-CORE初识/">Spark CORE初识</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/07/Spark RDD理解/">Spark RDD理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/07/MR任务的三种运行方式/">MR任务的三种运行方式</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/19/使用Phoenix将SQL代码移植至HBase/">使用Phoenix将SQL代码移植至HBase</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/09/Spark源码编译/">Spark源码编译</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/28/Scala基本语法和知识点/">Scala基本语法和知识点</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/30/memcached缓存安装配置/">memcached缓存安装配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/30/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>