<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="大数据技术整理文档"><title>Spark RDD理解 | 博客</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark RDD理解</h1><a id="logo" href="/.">博客</a><p class="description">IT技术博客</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark RDD理解</h1><div class="post-meta">Feb 20, 2017<span> | </span><span class="category"><a href="/categories/Spark/">Spark</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-RDD是什么，通过读取HDFS上数据理解"><span class="toc-number">1.</span> <span class="toc-text">Spark RDD是什么，通过读取HDFS上数据理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-RDD五大特性的理解，结合RDD源码"><span class="toc-number">2.</span> <span class="toc-text">Spark RDD五大特性的理解，结合RDD源码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD创建的两种方式、RDD三大Operations-Transformation、Action及Persist-使用理解"><span class="toc-number">3.</span> <span class="toc-text">RDD创建的两种方式、RDD三大Operations(Transformation、Action及Persist)使用理解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD的创建方式"><span class="toc-number">3.1.</span> <span class="toc-text">RDD的创建方式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#第一种方式："><span class="toc-number">3.1.1.</span> <span class="toc-text">第一种方式：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#第二种方式："><span class="toc-number">3.1.2.</span> <span class="toc-text">第二种方式：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD函数类型"><span class="toc-number">3.2.</span> <span class="toc-text">RDD函数类型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Transformation-算子-：-在Driver中执行"><span class="toc-number">3.2.1.</span> <span class="toc-text">Transformation(算子)：(在Driver中执行)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Action-算子-在Executors中执行"><span class="toc-number">3.2.2.</span> <span class="toc-text">Action(算子): (在Executors中执行)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Persist"><span class="toc-number">3.2.3.</span> <span class="toc-text">Persist:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程"><span class="toc-number">4.</span> <span class="toc-text">Spark Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark优化-两阶段聚合"><span class="toc-number">5.</span> <span class="toc-text">Spark优化-两阶段聚合</span></a></li></ol></div></div><div class="post-content"><h3 id="Spark-RDD是什么，通过读取HDFS上数据理解"><a href="#Spark-RDD是什么，通过读取HDFS上数据理解" class="headerlink" title="Spark RDD是什么，通过读取HDFS上数据理解"></a>Spark RDD是什么，通过读取HDFS上数据理解</h3><h3 id="Spark-RDD五大特性的理解，结合RDD源码"><a href="#Spark-RDD五大特性的理解，结合RDD源码" class="headerlink" title="Spark RDD五大特性的理解，结合RDD源码"></a>Spark RDD五大特性的理解，结合RDD源码</h3><p>RDD主要有五大特性，这些特性保证了Spark的扩展性、容错性等特征，主要特性如下：</p>
<ul>
<li><p>RDD是一个分区的集合（RDD是一个分布在不同机器上的数据集）（一系列的分片：比如说64M一片；类似于Hadoop中的split）</p>
</li>
<li><p>RDD的每一个分区都有一个compute函数进行数据计算（在每个分片都有一个函数去迭代/执行/计算它）</p>
</li>
<li><p>每个RDD都依赖其它RDD（RDD的lineage特性，生命线），功能是当RDD执行失败的时候，可以从父RDD重新执行，进行job的回复（一系列的依赖：RDDa转换为RDDb，RDDb转换为RDDc，那么RDDc就依赖于RDDb，RDDb就依赖于RDDa）</p>
</li>
<li><p>对于Key-Value键值对类型的RDD，存在一个数据分区器，默认数据分区器为HashPartitioner，根据key的hashcode值决定该数据到下一个RDD的分区id（对于key-value的RDD可指定一个partitioner，告诉它如何分片；常用的有hash，range）</p>
</li>
<li><p>数据计算本地化特性（要运行的计算/执行最好在哪（几）个机器上。数据本地性为什么会有哪几个呢？比如：hadoop默认有三个位置，或者spark cache到内存是可能通过StorageLevel设置了多个副本，所以一个partiton可能返回多个最佳位置）<br><img src="http://static.zybuluo.com/yangzsh/pdfvj7dacqolbpv80zbu1ktd/RDD%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84.png" alt="RDD逻辑结构.png-134.8kB"></p>
</li>
</ul>
<h3 id="RDD创建的两种方式、RDD三大Operations-Transformation、Action及Persist-使用理解"><a href="#RDD创建的两种方式、RDD三大Operations-Transformation、Action及Persist-使用理解" class="headerlink" title="RDD创建的两种方式、RDD三大Operations(Transformation、Action及Persist)使用理解"></a>RDD创建的两种方式、RDD三大Operations(Transformation、Action及Persist)使用理解</h3><h4 id="RDD的创建方式"><a href="#RDD的创建方式" class="headerlink" title="RDD的创建方式"></a>RDD的创建方式</h4><p>两种创建方式：<br>There are two ways to create RDDs: parallelizing an existing collection in your driver program, or referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat.</p>
<h5 id="第一种方式："><a href="#第一种方式：" class="headerlink" title="第一种方式："></a>第一种方式：</h5><p>作用：主要用于测试<br>序列化已经存在的一个scala的集合产生RDD<br><a href="http://spark.apache.org/docs/1.6.1/programming-guide.html#parallelized-collections" target="_blank" rel="external">http://spark.apache.org/docs/1.6.1/programming-guide.html#parallelized-collections</a><br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">eg:</div><div class="line">val data = Array(1, 2, 3, 4, 5)</div><div class="line">val distData = sc.parallelize(data)</div><div class="line">distData.map(v =&gt; (v%2,1)).reduceByKey(_+_).collect()</div></pre></td></tr></table></figure></p>
<h5 id="第二种方式："><a href="#第二种方式：" class="headerlink" title="第二种方式："></a>第二种方式：</h5><p>作用：生成环境中使用<br>读取存储在外部数据源中的数据并形成RDD返回<br><a href="http://spark.apache.org/docs/1.6.1/programming-guide.html#external-datasets" target="_blank" rel="external">http://spark.apache.org/docs/1.6.1/programming-guide.html#external-datasets</a><br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">val distFile</span> = sc.textFile(<span class="string">"data.txt"</span>)</div></pre></td></tr></table></figure></p>
<h4 id="RDD函数类型"><a href="#RDD函数类型" class="headerlink" title="RDD函数类型"></a>RDD函数类型</h4><h5 id="Transformation-算子-：-在Driver中执行"><a href="#Transformation-算子-：-在Driver中执行" class="headerlink" title="Transformation(算子)：(在Driver中执行)"></a>Transformation(算子)：(在Driver中执行)</h5><p>执行策略是Lazy<br>从一个RDD产生一个新的RDD， RDD[T] ==&gt; RDD[U]<br>当一个RDD调用transfromation类型的函数的时候，只是在内部构建了一个DAG的执行图(基于RDD的依赖)，当RDD被触发的时候，DAG执行图开始执行</p>
<h5 id="Action-算子-在Executors中执行"><a href="#Action-算子-在Executors中执行" class="headerlink" title="Action(算子): (在Executors中执行)"></a>Action(算子): (在Executors中执行)</h5><p>立即执行<br>当一个RDD产生的结果不是RDD的时候，认为是一个Action(动作), RDD[T] ==&gt; OtherType<br>Action动作的执行会导致在transformation过程中构建的DAG图被执行(被提交到运行节点上去执行)<br>Spark的job的提交运行最终由SparkContext中的runJob函数负责，会将RDD构建的DAG执行图进行一系列的划分，最终提交到Executors中执行任务</p>
<h5 id="Persist"><a href="#Persist" class="headerlink" title="Persist:"></a>Persist:</h5><p>将RDD中的数据进行持久化或者反持久化操作<br>持久化级别（StorageLevel）：RDD默认是内存<br><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> NONE = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>)</div><div class="line"><span class="keyword">val</span> DISK_ONLY = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>)</div><div class="line"><span class="keyword">val</span> DISK_ONLY_2 = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_ONLY = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_ONLY_2 = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">true</span>, <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_ONLY_SER = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_ONLY_SER_2 = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_AND_DISK = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_AND_DISK_2 = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">true</span>, <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_AND_DISK_SER = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>)</div><div class="line"><span class="keyword">val</span> MEMORY_AND_DISK_SER_2 = <span class="keyword">new</span> StorageLevel(<span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> OFF_HEAP = <span class="keyword">new</span> StorageLevel(<span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">true</span>, <span class="keyword">false</span>)</div></pre></td></tr></table></figure></p>
<p>1.方法：</p>
<p>持久化：是lazy的，只有当有action被触发的时候，才会进行持久化操作；RDD执行的时候，会从持久化的RDD中读取数据，不会重新执行父RDD的代码逻辑</p>
<ul>
<li>cache：内部调用persist</li>
<li>persist: 内部调用persist(MEMORY_ONLY)</li>
<li>persist(StorageLevel): 给定级别进行RDD数据缓存，要求这个RDD没有进行过缓存</li>
</ul>
<p>反持久化：立即执行的</p>
<ul>
<li>unpersist: 删除持久化的数据</li>
</ul>
<p>2.总结</p>
<p>持久化：当调用cache函数进行持久化操作的时候，如果内存不够，不会cache所有数据，只会cache一部分数据(按照分区进行cache的)</p>
<p>3.注意：<br>一般在RDD不使用的时候，要调用unpersist函数进行持久化的RDD删除<br>持久化的级别一般选择为：<br>MEMORY_ONLY<br>MEMORY_ONLY_SER<br>MEMORY_AND_DISK<br>除非数据不能丢失，而且计算过后，父RDD没法重新计算数据的，在RDD缓存的时候，才使用X2的级别<br><a href="http://www.cnblogs.com/luogankun/p/3801047.html" target="_blank" rel="external">RDD缓存策略</a></p>
<p>4.RDD API<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="attr">map:</span> 转换，按条进行数据转换</div><div class="line"><span class="attr">flatMap:</span> 转换+结果扁平化</div><div class="line">filter：过滤数据</div><div class="line">mapPartitions：转换，按分区进行分区的数据转换</div><div class="line">repartition：重置分区，内部调度coalesce</div><div class="line">coalesce：重置分区；当分区数量减少的时候，可以将参数shuffle设置为<span class="literal">false</span></div><div class="line">distinct：去重用</div><div class="line">reduceByKey：按照key进行聚合，聚合后类型和RDD的V类型必须一样</div><div class="line">aggregateByKey：按照key进行聚合，聚合后类型和RDD的V类型可以不一样</div><div class="line"><span class="attr">groupByKey:</span>按照Key进行数据聚合，防止出现OOM异常</div><div class="line"><span class="attr">sortByKey:</span> 按照key进行数据排序</div><div class="line"><span class="attr">zip:</span> 拉链操作，将两个RDD合并</div><div class="line">zipPartitions：zip底层实现，按照分区进行RDD的合并</div><div class="line">zipWithIndex：RDD的数据和序列号进行拉链操作及合并</div><div class="line">zipWithUniqueId：RDD和一个唯一的id进行拉链操作</div><div class="line"></div><div class="line"><span class="attr">foreach:</span> 对每条数据进行操作，一般不用</div><div class="line"><span class="attr">foreachPartition:</span> 对每个分区的数据进行操作，常用</div><div class="line">top：获取topN</div><div class="line">take：获取前多少个</div><div class="line"><span class="attr">saveXXXX:</span> 将数据通过Hadoop的OutputFormat类进行数据输出</div></pre></td></tr></table></figure></p>
<p>5.扩展：<br>SparkRDD不进行cache操作，后面的操作也比前面的操作快，原因是(第二次执行比第一次快)：Spark对将job的执行缓存一段时间(缓存到磁盘/内存)，当第二次执行的时候，会自动从磁盘/内存中获取，不需要重新执行父RDD的代码逻辑 </p>
<h3 id="Spark-Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程"><a href="#Spark-Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程" class="headerlink" title="Spark Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程"></a>Spark Core案例讲解，必要掌握，主要是RDD的使用，Scala语言编程</h3><h3 id="Spark优化-两阶段聚合"><a href="#Spark优化-两阶段聚合" class="headerlink" title="Spark优化-两阶段聚合"></a>Spark优化-两阶段聚合</h3></div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://yangzsh.github.io/2017/02/20/Spark RDD理解/" data-id="cizdwvryr0001coqzkn88d8dl" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Spark-RDD/">Spark RDD</a></div><div class="post-nav"><a href="/2017/02/09/Spark-CORE初识/" class="next">Spark CORE初识</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://yangzsh.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HBase二次索引/">HBase二次索引</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/">Scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境搭建/">环境搭建</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/MR开发环境搭建/" style="font-size: 15px;">MR开发环境搭建</a> <a href="/tags/Spark-RDD/" style="font-size: 15px;">Spark RDD</a> <a href="/tags/Spark源码编译/" style="font-size: 15px;">Spark源码编译</a> <a href="/tags/Spark-CORE/" style="font-size: 15px;">Spark CORE</a> <a href="/tags/Phoenix/" style="font-size: 15px;">Phoenix</a> <a href="/tags/Scala语法/" style="font-size: 15px;">Scala语法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/02/20/Spark RDD理解/">Spark RDD理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/09/Spark-CORE初识/">Spark CORE初识</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/07/MR任务的三种运行方式/">MR任务的三种运行方式</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/19/使用Phoenix将SQL代码移植至HBase/">使用Phoenix将SQL代码移植至HBase</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/09/Spark源码编译/">Spark源码编译</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/28/Scala基本语法和知识点/">Scala基本语法和知识点</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/30/memcached缓存安装配置/">memcached缓存安装配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/30/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>